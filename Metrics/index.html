<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Metrics - MISCnn wiki</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Metrics";
    var mkdocs_page_input_path = "Metrics.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> MISCnn wiki</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../Home/">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Getting Started</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../Home/">What is MIScnn?</a>
                </li>
                <li class="">
                    
    <a class="" href="../Install/">Install</a>
                </li>
                <li class="">
                    
    <a class="" href="../Usage/">Basic Usage</a>
                </li>
                <li class="">
                    
    <a class="" href="../Tutorials/">Tutorials</a>
                </li>
                <li class="">
                    
    <a class="" href="../Examples/">Examples</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Documentation - Core</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../Data-IO/">Data I/O</a>
                </li>
                <li class="">
                    
    <a class="" href="../Preprocessor/">Preprocessor</a>
                </li>
                <li class="">
                    
    <a class="" href="../Data-Augmentation/">Data Augmentation</a>
                </li>
                <li class="">
                    
    <a class="" href="../Model/">Neural Network Model</a>
                </li>
                <li class="">
                    
    <a class="" href="../Validation/">Validation Techniques</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Documentation - Interfaces</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../Architectures/">Architectures</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">Metrics</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#usage-of-loss-functions-and-metrics">Usage of loss functions and metrics</a></li>
    

    <li class="toctree-l3"><a href="#available-loss-functions-and-metrics-provided-by-miscnn">Available loss functions and metrics provided by MIScnn</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#tversky-loss">Tversky loss</a></li>
        
            <li><a class="toctree-l4" href="#sum-of-tversky-loss-and-cross-entropy">Sum of Tversky loss and Cross-entropy</a></li>
        
            <li><a class="toctree-l4" href="#dice-similarity-coefficient-dsc">Dice Similarity Coefficient (DSC)</a></li>
        
            <li><a class="toctree-l4" href="#soft-dice-similarity-coefficient">Soft Dice Similarity Coefficient</a></li>
        
            <li><a class="toctree-l4" href="#sum-of-soft-dice-similarity-coefficient-and-cross-entropy">Sum of Soft Dice Similarity Coefficient and Cross-entropy</a></li>
        
        </ul>
    

    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../Subfunctions/">Subfunctions</a>
                </li>
                <li class="">
                    
    <a class="" href="../IO-Interfaces/">I/O Interfaces</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Documentation - Extras</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../Sample/">Sample</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Other</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../Contribute/">How to Contribute</a>
                </li>
                <li class="">
                    
    <a class="" href="../Credits/">Author and Contacts</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">MISCnn wiki</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>Documentation - Interfaces &raquo;</li>
        
      
    
    <li>Metrics</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <p>A loss function or metric (or objective function, or optimization score function) is a scoring function to evaluate the current predictive power and performance of a model.</p>
<p>A loss function is required for training and have to be decreasing, if the model performance is increasing. During the training process, the neural network model varies weights of its neurons and tries to optimize the loss function to be as small as possible. A model can only use one loss function.</p>
<p>Metrics are for user evaluation in order to give insights on the training process or the current performance status of the model. It is possible to pass multiple metrics to the model.</p>
<p>MIScnn loss functions and metrics are based on Keras loss/metric functions.<br />
Any loss or metric function defined in Keras, in miscnn.neural_network.metrics or any custom function, which follows the Keras metric guidelines, can be used in MIScnn.</p>
<h2 id="usage-of-loss-functions-and-metrics">Usage of loss functions and metrics</h2>
<p>The loss function and metrics can be defined at the neural network model class initialization.<br />
It is possible to pass the desired loss function with the 'loss' tag and the metrics within a standard python list with the 'metrics' tag.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import desired loss functions or metrics</span>
<span class="kn">from</span> <span class="nn">miscnn.neural_network.metrics</span> <span class="kn">import</span> <span class="n">tversky_loss</span><span class="p">,</span> <span class="n">dice_soft</span>
<span class="kn">import</span> <span class="nn">keras</span>

<span class="c1"># Add the loss function &amp; metrics to the neural network model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Neural_Network</span><span class="p">(</span><span class="n">preprocessor</span><span class="o">=</span><span class="n">pp</span><span class="p">,</span>
                       <span class="n">loss</span><span class="o">=</span><span class="n">tversky_loss</span><span class="p">,</span>
                       <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">dice_soft</span><span class="p">,</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">categorical_crossentropy</span><span class="p">])</span>
</pre></div>
</td></tr></table>

<p>If no loss or metrics are provided, MIScnn uses the Tversky loss function and no metrics as default.</p>
<h2 id="available-loss-functions-and-metrics-provided-by-miscnn">Available loss functions and metrics provided by MIScnn</h2>
<h4 id="tversky-loss">Tversky loss</h4>
<p>A generalized loss function based on the Tversky index to address the issue of data imbalance and achieve much better trade-off between precision and recall in training 3D fully convo- lutional deep neural networks.<br />
Reference: <a href="https://arxiv.org/abs/1706.05721">https://arxiv.org/abs/1706.05721</a></p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">miscnn.neural_network.metrics</span> <span class="kn">import</span> <span class="n">tversky_loss</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Neural_Network</span><span class="p">(</span><span class="n">preprocessor</span><span class="o">=</span><span class="n">pp</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">tversky_loss</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<hr />
<h4 id="sum-of-tversky-loss-and-cross-entropy">Sum of Tversky loss and Cross-entropy</h4>
<p>Based on the idea of Fabian Isensee et al. for using the sum of the Dice Similarity Coefficient and the Cross-Entropy, MIScnn implemented a loss function based on the sum of the Tversky loss &amp; Cross-Entropy loss function.<br />
Reference Fabian Isensee et al: <a href="http://arxiv.org/abs/1809.10486">http://arxiv.org/abs/1809.10486</a></p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">miscnn.neural_network.metrics</span> <span class="kn">import</span> <span class="n">tversky_crossentropy</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Neural_Network</span><span class="p">(</span><span class="n">preprocessor</span><span class="o">=</span><span class="n">pp</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">tversky_crossentropy</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<hr />
<h4 id="dice-similarity-coefficient-dsc">Dice Similarity Coefficient (DSC)</h4>
<p>The Dice Similarity Coefficient is one the most popular loss functions for training deep learning models in medical image segmentation. It has the ability the handle strong class imbalance which is common in medical imaging. The standard Dice Similarity Coefficient is suited for binary medical image segmentation problems.<br />
Reference: -&gt;  add wikipedia link</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">miscnn.neural_network.metrics</span> <span class="kn">import</span> <span class="n">dice_coefficient_loss</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Neural_Network</span><span class="p">(</span><span class="n">preprocessor</span><span class="o">=</span><span class="n">pp</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">dice_coefficient_loss</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<hr />
<h4 id="soft-dice-similarity-coefficient">Soft Dice Similarity Coefficient</h4>
<p>The Soft Dice Similarity Coefficient is an extension of the standard Dice Similarity Coeffcient. The only difference is, that the soft DSC is normalized on the number of classes. Therefore, the soft Dice Similarity Coefficient is more suited for multi-class (&gt;2 classes) medical image segmentation problems.<br />
Reference: -&gt;  add wikipedia link</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">miscnn.neural_network.metrics</span> <span class="kn">import</span> <span class="n">dice_soft_loss</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Neural_Network</span><span class="p">(</span><span class="n">preprocessor</span><span class="o">=</span><span class="n">pp</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">dice_soft_loss</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<hr />
<h4 id="sum-of-soft-dice-similarity-coefficient-and-cross-entropy">Sum of Soft Dice Similarity Coefficient and Cross-entropy</h4>
<p>In diverse medical image segmentation challenges, the winner Fabian Isensee et al. is always using the sum of the soft Dice Similarity Coeffcient and the Cross-Entropy in order to achieve the best performance. Additionally, Fabian Isensee et al. also uses this loss function in his powerful software nnUnet.<br />
Reference: <a href="http://arxiv.org/abs/1809.10486">http://arxiv.org/abs/1809.10486</a></p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">miscnn.neural_network.metrics</span> <span class="kn">import</span> <span class="n">dice_crossentropy</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Neural_Network</span><span class="p">(</span><span class="n">preprocessor</span><span class="o">=</span><span class="n">pp</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">dice_crossentropy</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<hr />
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../Subfunctions/" class="btn btn-neutral float-right" title="Subfunctions">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../Architectures/" class="btn btn-neutral" title="Architectures"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../Architectures/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../Subfunctions/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
